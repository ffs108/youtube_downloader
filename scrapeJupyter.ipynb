{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf842c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting link retrival.\n",
      "Link appended; 38 remaining.\n",
      "Link appended; 37 remaining.\n",
      "Link appended; 36 remaining.\n",
      "Link appended; 35 remaining.\n",
      "Link appended; 34 remaining.\n",
      "Link appended; 33 remaining.\n",
      "Link appended; 32 remaining.\n",
      "Link appended; 31 remaining.\n",
      "Link appended; 30 remaining.\n",
      "Link appended; 29 remaining.\n",
      "Link appended; 28 remaining.\n",
      "Link appended; 27 remaining.\n",
      "Link appended; 26 remaining.\n",
      "Link appended; 25 remaining.\n",
      "Link appended; 24 remaining.\n",
      "Link appended; 23 remaining.\n",
      "Link appended; 22 remaining.\n",
      "Link appended; 21 remaining.\n",
      "Link appended; 20 remaining.\n",
      "Link appended; 19 remaining.\n",
      "Link appended; 18 remaining.\n",
      "Link appended; 17 remaining.\n",
      "Link appended; 16 remaining.\n",
      "Link appended; 15 remaining.\n",
      "Link appended; 14 remaining.\n",
      "Link appended; 13 remaining.\n",
      "Link appended; 12 remaining.\n",
      "Link appended; 11 remaining.\n",
      "Link appended; 10 remaining.\n",
      "Link appended; 9 remaining.\n",
      "Link appended; 8 remaining.\n",
      "Link appended; 7 remaining.\n",
      "Link appended; 6 remaining.\n",
      "Link appended; 5 remaining.\n",
      "Link appended; 4 remaining.\n",
      "Link appended; 3 remaining.\n",
      "Link appended; 2 remaining.\n",
      "Link appended; 1 remaining.\n",
      "Link appended; 0 remaining.\n",
      "Linked retrival completed.\n",
      "Beginning link parse.\n"
     ]
    },
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(79644 bytes read, 4132276 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#print(urls)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     yt_scrape(urls)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m urls \u001b[38;5;241m=\u001b[39m link_grab(track_list, name_list)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#print(urls)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[43myt_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43murls\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m, in \u001b[0;36myt_scrape\u001b[1;34m(url_list)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[0;32m     15\u001b[0m     yt \u001b[38;5;241m=\u001b[39m YouTube(url)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43myt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogressive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo scraped count: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(counter))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytube\\streams.py:314\u001b[0m, in \u001b[0;36mStream.download\u001b[1;34m(self, output_path, filename, filename_prefix, skip_existing, timeout, max_retries)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m request\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m    316\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    317\u001b[0m             max_retries\u001b[38;5;241m=\u001b[39mmax_retries\n\u001b[0;32m    318\u001b[0m         ):\n\u001b[0;32m    319\u001b[0m             \u001b[38;5;66;03m# reduce the (bytes) remainder by the length of the chunk.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m             bytes_remaining \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;66;03m# send to the on_progress callback.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytube\\request.py:189\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(url, timeout, max_retries)\u001b[0m\n\u001b[0;32m    187\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(e)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:471\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:614\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    612\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m--> 614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(79644 bytes read, 4132276 more expected)"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import re, urllib.request, urllib.parse\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "DOWNLOAD_DIR = r'D:\\\\Pancho_Resume\\\\Python_projects\\\\spotifyJupyter\\\\dlTarget'\n",
    "TESTING_LENGTH = 577\n",
    "\n",
    "\n",
    "\n",
    "def yt_scrape(url_list):\n",
    "    counter = 0\n",
    "    print('Beginning link parse.')\n",
    "    for url in url_list:\n",
    "        yt = YouTube(url)\n",
    "        yt.streams.filter(progressive=True, file_extension='mp4').first().download(output_path=DOWNLOAD_DIR)\n",
    "        counter += 1\n",
    "        print('Video scraped count: '+ str(counter))\n",
    "    \n",
    "\n",
    "def link_grab(tracks, artists):\n",
    "    print('Starting link retrival.')\n",
    "    retval = []\n",
    "    if len(tracks) == len(artists):\n",
    "        for i in range(541, len(tracks)):\n",
    "            #need to search and grab the url associated with each link\n",
    "            search = urllib.parse.urlencode({'search_query': tracks[i] + 'by' + artists[i]})\n",
    "            html = urllib.request.urlopen(\"http://www.youtube.com/results?\" + search)\n",
    "            video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.read().decode())\n",
    "            try:\n",
    "                #print(\"https://www.youtube.com/watch?v=\" + video_ids[0])\n",
    "                link = \"https://www.youtube.com/watch?v=\" + video_ids[0] #in address grab 1st vid\n",
    "                retval.append(link)\n",
    "                print('Link appended; ' + str((len(tracks) - (i+1))) + ' remaining.')\n",
    "            except IndexError:\n",
    "                pass\n",
    "        print('Linked retrival completed.')\n",
    "        return retval\n",
    "    else:\n",
    "        return retval\n",
    "    \n",
    "    \n",
    "def file_read(fname):\n",
    "    relevant = [\"Track Name\",\"Artist Name(s)\",\"Genre\"]\n",
    "    df = pd.read_csv(fname).filter(items=relevant)\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    fname = \"lucifer_soundtrack_all_seasons.csv\"\n",
    "    df = file_read(fname)\n",
    "    name_list = df[\"Artist Name(s)\"].tolist()\n",
    "    track_list = df[\"Track Name\"]\n",
    "    urls = link_grab(track_list, name_list)\n",
    "    #print(urls)\n",
    "    yt_scrape(urls)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
